- name: Build EC2 Instance
  hosts: localhost
  gather_facts: false
  vars:
    # t2.small for building node JS applications and docker files 
    pik_build_server_size: t2.small
    # t2.micro for running NodeJS/nginx/Postgres
    pik_live_server_size: t2.micro
  # Secrets Manager to store runtime application secrets
  # IAM role and policy to access secrets
  # Creates VPC 
  # 2 security groups for ELB to EC2 connection
  # EC2 Key Pair 
  # Generate EC2 Build Image Server
  # Generates AMI from EC2 Image 
  # Deletes Build Server
  tasks: 
    - assert:
        that:
        - aws_access_key != ""
        - aws_secret_key != ""
        - app_git_repo != ""
        - app_git_branch != ""
        # - conf_api_url != ""
        # - conf_db_host != ""
        # - conf_db_port != ""
        # - conf_db_user != ""
        # - conf_db_pass != ""
    - name: Set AWS default varaibles
      set_fact:
        aws_region: ap-southeast-2
        tag_ec2_creation_time: "{{ '%Y%m%d-%H%M%S' | strftime }}"
    - name: Create Secrets Manager 
      include_role: 
        name: create_secrets_manager
      vars: 
        secrets_name: pik-build-sm
        # The only reason we pass in secrets to this playbook is so the build script can generate a valid build script to uat.
        # Now this is done, we can fill this in with dummy values and clean up the GHA further. 
        conf_db_host: "127.0.0.1"
        conf_db_port: "5432"
        conf_db_user: "dumb"
        conf_db_pass: "dumber"
        conf_api_url: "http://api.dummy.com"
    - name: Create IAM roles 
      include_role:
        name: create_ec2_iam_role
      vars:
        iam_role_name: pik-auto-ec2-test
        secrets_manager_arn: "{{ secrets_result.secret.arn }}"
        region: "{{ aws_region }}"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
    - name: DEBUG iam result 
      debug: 
        var: iam_ec2_role_result
    - name: Create VPC "pik-build-vpc"
      include_role: 
        name: create_app_vpc
      vars:
        # VPC Name
        vpc_name: "pik-build-vpc"
        # Internet Gateway Name
        igw_name: "pik-build-igw"
        region: "{{ aws_region }}"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        # Values could be 
        # 10.0.0.0/16
        # 10.0.0.0/24
        cidr_block: "10.0.0.0/16" 
        # Subnet AZ
        subnet_1_cidr_block: "10.0.0.0/20"
        subnet_2_cidr_block: "10.0.16.0/20"
        subnet_3_cidr_block: "10.0.32.0/20"
        route_table_name: "pik-build-rtb-public"
        # Route destination CIDR to global internet
        destination_cidr_block: "0.0.0.0/0"
    - name: Create EC2 Security Group "pik-build-ec2-sg"
      amazon.aws.ec2_group:
        name: pik-build-ec2-sg
        description: Security group for build EC2 servers
        region: "{{ aws_region }}"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        vpc_id: "{{ pik_vpc_net_result.vpc.id }}"
        rules:
          # Allow global SSH
          - proto: tcp
            from_port: 22
            to_port: 22
            cidr_ip: 0.0.0.0/0
            group_desc: Allow global SSH access
        rules_egress:
          - proto: all
            cidr_ip: 0.0.0.0/0
            group_desc: Allow all traffic outbound
        state: present
      register: ec2_sg_result
      tags: create_sg
    - name: Display EC2 SG details
      debug:
        msg: "EC2 Security Group ID: {{ ec2_sg_result.group_id }}"
    - name: Create ELB Security Group "pik-build-elb-sg"
      ec2_group:
        name: "pik-build-elb-sg"
        description: "Security group for build ELB"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        aws_region: "{{ aws_region }}"
        vpc_id: "{{ pik_vpc_net_result.vpc.id }}"
        rules:
          # Global HTTP ingress 
          - proto: tcp
            from_port: 80
            to_port: 80
            cidr_ip: 0.0.0.0/0
            group_desc: Global HTTP traffic inbound
          # Global HTTP ingress
          - proto: tcp
            from_port: 443
            to_port: 443
            cidr_ip: 0.0.0.0/0
            group_desc: Global HTTPS traffic inbound
        rules_egress:
          # ELB access RDS 
          - proto: tcp
            from_port: 5432
            to_port: 5432
            group_id: "{{ ec2_sg_result.group_id }}"
            group_desc: ELB access EC2 API egress
          # ELB access EC2 on to API
          - proto: tcp
            from_port: 4000
            to_port: 4000
            group_id: "{{ ec2_sg_result.group_id }}"
            group_desc: ELB access EC2 API egress
          # ELB access EC2 on to FE
          - proto: tcp
            from_port: 5000
            to_port: 5000
            group_id: "{{ ec2_sg_result.group_id }}"
            group_desc: ELB access EC2 FE egress
      register: elb_sg_result
    - name: Add ELB access to EC2 in SG rules
      amazon.aws.ec2_group:
        name: "pik-build-ec2-sg"
        # Add rules, don't replaces
        purge_rules: false
        purge_rules_egress: false
        description: "Security group for build EC2 servers"
        region: "{{ aws_region }}"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        vpc_id: "{{ pik_vpc_net_result.vpc.id }}"
        rules:
          - proto: tcp
            from_port: 4000
            to_port: 4000
            group_id: "{{ elb_sg_result.group_id }}"
            group_desc: ELB access to API
          - proto: tcp
            from_port: 5000
            to_port: 5000
            group_id: "{{ elb_sg_result.group_id }}"
            group_desc: ELB access to FE
        rules_egress:
          - proto: all
            cidr_ip: 0.0.0.0/0
            group_desc: Allow all traffic outbound
        state: present
      register: ec2_sg_result
    - name: Display ELB SG details
      debug:
        msg: "ELB Security Group ID: {{ elb_sg_result.group_id }}"    
    # - name: Debug Delete EC2 Key Pair
    #   ec2_key:
    #     name: pik-keypair
    #     region: "{{ aws_region }}"
    #     aws_access_key: "{{ aws_access_key }}"
    #     aws_secret_key: "{{ aws_secret_key }}"    
    #     state: absent
    #   register: delete_keypair
    # - name: Debug delete_keypair 
    #   debug: 
    #     var: delete_keypair
    - name: Create EC2 Key Pair
      ec2_key:
        name: pik-build-keypair
        region: "{{ aws_region }}"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"    
      register: keypair_result
    - debug: 
        var: keypair_result
    # Save key pair 
    - name: Display the private key (only if created)
      debug:
        msg: "{{ keypair_result.key.private_key | default('Key already exists, no private key returned.') }}"
    - name: Save private key to a file
      copy:
        content: "{{ keypair_result.key.private_key | default('') }}"
        dest: "./pik-keypair.pem"
        mode: '0400'
      when: keypair_result.key.private_key is defined
    # Create the EC2 instance. Run scripst to set up application 
    - name: Create EC2 Build Server
      amazon.aws.ec2_instance:
        # Ensure EC2 instance is created running 
        state: running 
        # state: present 
        region: "{{ aws_region }}"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        # Instance name - auto generated 
        name: "pik-build-{{ tag_ec2_creation_time }}"
        iam_instance_profile: "{{ iam_instance_profile_arn_result }}"
        # User Data Script in bash. sudo included so script can be copy+pasted into a failed build 
        # EC2 for easier debugging. 
        user_data: |
          #!/bin/bash
          # Lay my claim
          echo test message > /etc/quinn-wuz-here
          # Test secret dumping
          echo AWS_ACCESS_KEY={{ aws_access_key }} >> /etc/quinn-wuz-here
          # Install necessary packages. Git, Docker
          apt-get update 
          # Install official Docker repo
          sudo apt-get install ca-certificates curl
          sudo install -m 0755 -d /etc/apt/keyrings
          sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
          sudo chmod a+r /etc/apt/keyrings/docker.asc
          # Add the repository to Apt sources:
          echo \
            "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
            $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
            sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
          sudo apt-get update
          # Install git
          sudo apt-get install -y git
          # Install docker and plugins 
          sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
          # Install aws cli 
          sudo apt-get install -y curl unzip  jq
          curl -o "awscliv2.zip" "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip"
          unzip -qq awscliv2.zip
          sudo ./aws/install
          aws --version
          # Clone application repository
          sudo mkdir /opt/app
          git clone {{ app_git_repo }} /tmp/app
          sudo mv /tmp/app /opt
          cd /opt/app
          git checkout {{ app_git_branch }}
          # Configure docker-compose file 
          sudo rm docker-compose.yml
          sudo cp docker-compose.deploy.yml docker-compose.yml
          # Run fetch-scripts to get secrets
          sudo bash fetch-secrets.sh
          # Compile all docker containers
          sudo docker compose up -d
          # Setup AusPohzt service 
          sudo chmod +x fetch-secrets.sh
          sudo cp auspohzt.service /etc/systemd/system/auspohzt.service
          sudo systemctl daemon-reload
          sudo systemctl enable auspohzt.service
          sudo systemctl start auspohzt.service
          sudo systemctl status auspohzt.service
        # SSH Key Pair Name 
        key_name: "pik-build-keypair"
        # Allow access to Tags 
        metadata_options:
          instance_metadata_tags: enabled
        # Subnet 1 
        vpc_subnet_id: "{{ pik_subnet_1_result.subnet.id }}"
        # Instance size. Bigger than t2.micro to build both apps at once
        instance_type: "{{ pik_build_server_size }}"
        security_group: "{{ ec2_sg_result.group_id }}"
        network_interfaces:
          - assign_public_ip: true
        # Ubuntu Server 24.04 LTS (HVM), SSD Volume Type
        image_id: ami-003f5a76758516d1e 
        tags:
          GitRepo: "{{ app_git_repo }}"
          GitBranch: "{{ app_git_branch }}"
          Created: "{{ tag_ec2_creation_time }}"
          Service: Pikachu 
          Environment: Build
          Owner: Ash Ketchum
          Automation: Ansible
          Source: https://github.com/wrong-commit/ansible-aws-deployment
          AWS_Secrets_Manager: pik-build-sm
      register: pik_ec2_result
    - name: Set next AMI variables 
      set_fact:
        pik_target_ami_instance: "{{ pik_ec2_result.instance_ids[0] }}"
        pik_target_ami_name: "Pikachu-Server-Ubuntu-24-04-LTS-{{ tag_ec2_creation_time }}"
        tag_ami_creation_time: "{{ '%Y%m%d-%H%M%S' | strftime }}"
    - name: Display Build Server Instance ID
      debug:
        msg: "EC2 Instance ID: {{ pik_target_ami_instance }}"
    # Create Target Group to get free health checks for EC2 build
    - name: Create EC2 Build Server Target Group 
      community.aws.elb_target_group:
        name: "pik-build-{{ tag_ec2_creation_time }}-tg"
        state: present
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        aws_region: "{{ aws_region }}"
        # Per Instance Target 
        target_type: instance
        # Listen on HTTP only
        protocol: http
        port: 80
        # VPC 
        vpc_id: "{{ pik_vpc_net_result.vpc.id }}"
        # Health check configuration
        health_check_protocol: http
        health_check_path: /healthcheck
        successful_response_codes: 200
        # Prod 15, UAT 5
        health_check_interval: 5
        # Prod 3
        health_check_timeout: 2
        # Prod 4
        healthy_threshold_count: 2
        # Prod 3
        unhealthy_threshold_count: 2
        # Define same target twice to check both services 
        targets:
          - Id: "{{ pik_target_ami_instance }}"
            Port: 4000
          - Id: "{{ pik_target_ami_instance }}"
            Port: 5000
      register: pik_elb_tg_result
    - debug:
        var: pik_elb_tg_result
    # Create Load Balancer for checking Target Group Health
    - name: Create Build Server Load Balancer 
      amazon.aws.elb_application_lb:
        name: "pik-build-{{ tag_ec2_creation_time }}-elb"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        aws_region: "{{ aws_region }}"
        security_groups:
          - "{{ elb_sg_result.group_id }}"
        subnets:
          - "{{ pik_subnet_1_result.subnet.id }}"
          - "{{ pik_subnet_2_result.subnet.id }}"
          - "{{ pik_subnet_3_result.subnet.id }}"
        listeners:
          - Protocol: HTTP # Required. The protocol for connections from clients to the load balancer (HTTP or HTTPS) (case-sensitive).
            Port: 80 # Required. The port on which the load balancer is listening.
            DefaultActions:
              - Type: forward # Required.
                TargetGroupName: "pik-build-{{ tag_ec2_creation_time }}-tg" # Required. The name of the target group
        state: present
      register: pik_elb_result
    # Get ELB Target Group Health Status
    - name: Get ELB Target Group Health Status
      community.aws.elb_target_group_info:
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
        aws_region: "{{ aws_region }}"
        # Include this to get `targets_health_description`
        collect_targets_health: true 
        names: 
          - "pik-build-{{ tag_ec2_creation_time }}-tg"
      register: 
        elb_status_result
      # Wait until both services are health
      until: 
        - elb_status_result.target_groups[0].targets_health_description[0].target_health.state == 'healthy'
        - elb_status_result.target_groups[0].targets_health_description[1].target_health.state == 'healthy'
      retries: 30 # Retry 15 times
      delay: 15   # Wait 15 seconds between retries
    - debug:
        var: elb_status_result
    - debug:
        msg: "App Port 1: {{ elb_status_result.target_groups[0].targets_health_description[0].target_health.state }}"
    - debug:
        msg: "App Port 2: {{ elb_status_result.target_groups[0].targets_health_description[1].target_health.state }}"
    - name: Display next AMI details
      debug:
        msg: "Next AMI name: {{ pik_target_ami_name }}"   
    # Stops the EC2 instance before creating AMI. 
    - name: Stop EC2 Build Server to create AMI  
      amazon.aws.ec2_instance:
        instance_ids: [ "{{ pik_target_ami_instance }}" ]
        state: stopped
        region: "{{ aws_region }}"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
    # Create AMI of running application
    - name: Create AMI of Build Server
      amazon.aws.ec2_ami: 
        # Need a way to version these. Might use commit hash, would prefer to use build variable consistent with git tag
        name: "{{ pik_target_ami_name }}"
        description: AMI for Pikachu application. Ubuntu Server 24.04 LTS (HVM). Built on {{ tag_ami_creation_time }}
        instance_id: "{{ pik_target_ami_instance }}"
        region: "{{ aws_region }}"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"    
        # Keep snapshots of build server after deleting AMI
        # delete_snapshot: false
        # Wait for the AMI to be available before returning. 40 mins
        wait: true
        wait_timeout: 2400
        # DEBUG: Disable rebooting build server to take AMI
        # no_reboot: true
        tags:
          GitRepo: "{{ app_git_repo }}"
          GitBranch: "{{ app_git_branch }}"
          Created: "{{ tag_ami_creation_time }}"
          Service: Pikachu 
          Environment: Build
          Owner: Ash Ketchum
          Automation: Ansible
          Source: "pik Build Server {{ pik_target_ami_instance }}"
      register: pik_ami_result
    - name: Debug AMI result 
      debug: 
        var: pik_ami_result
    # Restart the EC2 Build Server for debugging
    # - name: Start EC2 Build Server 
    #   amazon.aws.ec2_instance:
    #     instance_ids: [ "{{ pik_target_ami_instance }}" ]
    #     state: running 
    #     region: "{{ aws_region }}"
    #     aws_access_key: "{{ aws_access_key }}"
    #     aws_secret_key: "{{ aws_secret_key }}"
    # Delete Build Server on successful start
    - name: Delete EC2 Build Server 
      amazon.aws.ec2_instance:
        instance_ids: [ "{{ pik_target_ami_instance }}" ]
        state: terminated 
        region: "{{ aws_region }}"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_key }}"
    # Deploy new EC2 instance named 
    # - name: Deploy Built EC2 Image from AMI 
    #   amazon.aws.ec2_instance:
    #     # Instance name
    #     name: "pik-live-{{ tag_ec2_creation_time }}"
    #     # Most recently built AMI server
    #     image_id: "{{ pik_ami_result.image_id }}" 
    #     # Ensure EC2 instance is created running 
    #     state: running 
    #     region: "{{ aws_region }}"
    #     aws_access_key: "{{ aws_access_key }}"
    #     aws_secret_key: "{{ aws_secret_key }}"
    #     # SSH Key Pair Name 
    #     key_name: "pik-build-keypair"
    #     # Subnet 1 
    #     vpc_subnet_id: "{{ pik_subnet_1_result.subnet.id }}"
    #     # Instance size
    #     instance_type: "{{ pik_live_server_size }}"
    #     security_group: "{{ ec2_sg_result.group_id }}"
    #     network_interfaces:
    #       - assign_public_ip: true
    #     tags:
    #       Created: "{{ '%Y%m%d-%H%M%S' | strftime }}"
    #       Service: Pikachu 
    #       Environment: Production
    #       Owner: Ash Ketchum
    #       Automation: Ansible
    #       Source: https://github.com/wrong-commit/ansible-aws-deployment
    #   register: pik_live_ec2_result
    # - name: Debug AMI result 
    #   debug: 
    #     var: pik_live_ec2_result
